#!/usr/bin/env python3
"""
v1.1 20250321 Muhammet Nergizci, COMET - University of Leeds

========
Overview
========
This script applies absolute azimuth offsets (`daz`)—referenced in the ITRF2014 no-net-rotation frame—
to the residual cumulative displacement time-series (`cum`) of Burst Overlap Interferometry (BOI) results
generated by LiCSBAS. The aim is to convert the relative BOI time series into an absolute reference frame.

The corrected time-series (`cum_abs`) is written back into the original `cum.h5` file,
along with the corresponding referenced `daz` vector.

This script is intended to be used **after** the time-series inversion step 
(e.g., following `LiCSBAS13_sb_inv.py`) when per-epoch azimuth offsets (e.g., ICC+SD total shifts)
have already been estimated using `daz_lib_licsar`.

=====
Usage
=====
apply_daz_to_cum.py -t TS_DIR [-i cum_file]

 -t    Path to the LiCSBAS time-series directory (e.g., TS_GEOCml10)     [REQUIRED]
 -i    Name of the cumulative HDF5 file to process (default: cum.h5)     [OPTIONAL]

Example:
--------
python apply_daz_to_cum.py -t /path/to/TS_GEOCml10

This will:
 - Load the `cum.h5` time-series file from the specified folder
 - Read the pre-estimated `daz` (azimuth offsets) for each epoch via `daz_lib_licsar`
 - Interpolate `daz` to match the time steps of the BOI time-series cube
 - Reference both `cum` and `daz` to the first acquisition epoch
 - Save the absolute cumulative displacement (`cum_abs`) and aligned `daz` vector into `cum.h5`

==============
Output Variables
==============
 - cum_abs: absolute cumulative displacement (NumPy array of shape [ntime, ny, nx])
 - daz: interpolated and referenced azimuth offset time series (NumPy array of shape [ntime])

=============
Dependencies
=============
 - h5py, numpy, pandas, xarray
 - LiCSBAS libraries: `loadall2cube`, `daz_lib_licsar`
"""

#%% Change log
'''
v1.0 20250321 Muhammet Nergizci, COMET University of Leeds
- Original implementation
'''

#%% Import 
import os
import sys
import getopt
import h5py as h5
import numpy as np
import pandas as pd
import datetime as dt
from LiCSBAS_out2nc import loadall2cube
import daz_lib_licsar as dl

class Usage(Exception):
    """Usage context manager"""
    def __init__(self, msg):
        self.msg = msg


#%% Main
def main(argv=None):
    if argv is None:
        argv = sys.argv
        
        
    #%%Set defaults
    tsadir = ''
    cumfile = None
    
    #%% Read options
    try:
        opts, _ = getopt.getopt(argv[1:], "ht:i:", ["help"])
        for o, a in opts:
            if o in ("-h", "--help"):
                print(__doc__)
                return 0
            elif o == "-t":
                tsadir = a
            elif o == "-i":
                cumfile = a

        if not tsadir:
            raise Usage("TS directory not given. Use -t to specify.")
        if not os.path.isdir(tsadir):
            raise Usage(f"TS directory does not exist: {tsadir}")


    except Usage as err:
        print("\nERROR:", file=sys.stderr)
        print("  "+str(err.msg), file=sys.stderr)
        print("\nFor help, use -h or --help.\n", file=sys.stderr)
        return 2
    
    #%%Directory settings  ##I try to keep the LiCSBAS format structure (MN)
    framedir=os.getcwd()
    frame=os.path.basename(framedir)
    
    #%%Read data information
    if not cumfile:
        cumfile=os.path.join(tsadir,'cum.h5')
    else:
        if not os.path.exists(cumfile):
            print('Error reading specified input file, please fix')
            return 2
        
    #%%Load cumulative time-series cube
    print(f"Reading cum.h5 from: {cumfile}")

    with h5.File(cumfile, 'r') as f:
        cum = f['cum'][()]
        imdates = f['imdates'][()].astype(str)
        
    cum = cum - cum[0]  # reference to first epoch

    # Get daz values
    dazes = dl.get_daz_frame(frame)[['epoch', 'daz']]
    dazes['epoch'] = pd.to_datetime(dazes['epoch'])
    dazes['daz'] = dazes['daz'] * 14000  # convert to mm

    df_daz = pd.DataFrame({'epoch': pd.to_datetime(imdates)})
    df_daz = df_daz.merge(dazes, on='epoch', how='left').sort_values('epoch')
    df_daz['daz'] = df_daz['daz'].interpolate(method='nearest', limit_direction='both')
    daz = df_daz['daz'].to_numpy() - df_daz['daz'].iloc[0]  # align to first epoch

    # Apply correction
    cum_abs = cum + daz[:, None, None]

    print(f"Writing cum_abs to {cumfile} ...")
    with h5.File(cumfile, 'r+') as f:
        if 'cum_abs' in f:
            del f['cum_abs']
        f.create_dataset('cum_abs', data=cum_abs.astype('float32'), compression='gzip')

    print("absolute BOI's saved successfully.")
#%% main
if __name__ == "__main__":
    sys.exit(main())
